{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a51b2e",
   "metadata": {},
   "source": [
    "### Loading & Preprocessing Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b51d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratings = pd.read_csv(\n",
    "    \"data/ratings.dat\",\n",
    "    sep=\"::\",\n",
    "    engine=\"python\",\n",
    "    names=[\"user\", \"item\", \"rating\", \"timestamp\"]\n",
    ")\n",
    "\n",
    "ratings.drop(\"timestamp\", axis=1, inplace=True)\n",
    "\n",
    "user_ids = ratings[\"user\"].unique()\n",
    "item_ids = ratings[\"item\"].unique()\n",
    "user2idx = {u: i for i, u in enumerate(user_ids)}\n",
    "item2idx = {i: j for j, i in enumerate(item_ids)}\n",
    "\n",
    "ratings[\"user\"] = ratings[\"user\"].map(user2idx)\n",
    "ratings[\"item\"] = ratings[\"item\"].map(item2idx)\n",
    "\n",
    "n_users = len(user2idx)\n",
    "n_items = len(item2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb18fdd3",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d41bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(ratings, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8e3bdf",
   "metadata": {},
   "source": [
    "### User–Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02be31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built R matrix of shape (6040, 3706), with 800167 known entries.\n"
     ]
    }
   ],
   "source": [
    "# Initialize R with zeros\n",
    "R = np.zeros((n_users, n_items), dtype=np.float32)\n",
    "\n",
    "# Fill in with known ratings from train_df\n",
    "for row in train_df.itertuples():\n",
    "    R[row.user, row.item] = row.rating\n",
    "\n",
    "print(f\"Built R matrix of shape {R.shape}, \"\n",
    "      f\"with {np.count_nonzero(R)} known entries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02078db",
   "metadata": {},
   "source": [
    "### UserDataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c3d3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3706])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class UserDataset(Dataset):\n",
    "    def __init__(self, R_matrix):\n",
    "        # R_matrix: a NumPy array of shape (n_users, n_items)\n",
    "        self.R = torch.from_numpy(R_matrix)  # convert to tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.R.size(0)  # number of users\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # returns the ratings vector for user idx\n",
    "        return self.R[idx]\n",
    "\n",
    "# Instantiating dataset and loader\n",
    "batch_size = 64\n",
    "user_dataset = UserDataset(R)\n",
    "user_loader  = DataLoader(user_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Quick sanity check\n",
    "for batch in user_loader:\n",
    "    print(batch.shape)   # should print: (batch_size, n_items)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45b9de0",
   "metadata": {},
   "source": [
    "### AutoRec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03774421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class AutoRec(nn.Module):\n",
    "    def __init__(self, n_items, hidden_dim=512):\n",
    "        super(AutoRec, self).__init__()\n",
    "        # Encoder: from n_items → hidden_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(n_items, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Decoder: from hidden_dim → n_items\n",
    "        self.decoder = nn.Linear(hidden_dim, n_items)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, n_items)\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)  # reconstruction of shape (batch_size, n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b139b98",
   "metadata": {},
   "source": [
    "### Instantiating Model, Loss, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e368011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_dim = 512\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "\n",
    "# Instantiate and move to device\n",
    "ae_model = AutoRec(n_items, hidden_dim).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "optimizer_ae = torch.optim.Adam(\n",
    "    ae_model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8742845",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5a2bde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 3.6141\n",
      "Epoch 2/10, Train Loss: 1.8205\n",
      "Epoch 3/10, Train Loss: 1.2312\n",
      "Epoch 4/10, Train Loss: 1.0697\n",
      "Epoch 5/10, Train Loss: 1.0855\n",
      "Epoch 6/10, Train Loss: 1.0718\n",
      "Epoch 7/10, Train Loss: 0.9895\n",
      "Epoch 8/10, Train Loss: 0.9207\n",
      "Epoch 9/10, Train Loss: 0.7629\n",
      "Epoch 10/10, Train Loss: 0.6849\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    ae_model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in user_loader:\n",
    "        batch = batch.to(device)                  # shape: (batch_size, n_items)\n",
    "        output = ae_model(batch)                  # reconstruction\n",
    "\n",
    "        # Only compute loss on known ratings\n",
    "        mask = batch > 0                          # boolean mask\n",
    "        diff = (output - batch)[mask]             # errors on known entries\n",
    "        loss = (diff * diff).sum() / mask.sum()   # MSE over known entries\n",
    "\n",
    "        optimizer_ae.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_ae.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(user_loader)\n",
    "    print(f\"Epoch {epoch}/{num_epochs}, Train Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ab2e4",
   "metadata": {},
   "source": [
    "### Reconstructing & Evaluating on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e31feff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoRec Test RMSE: 1.0590\n",
      "AutoRec Test MAE:  0.8379\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ae_model.eval()\n",
    "with torch.no_grad():\n",
    "    R_tensor = torch.from_numpy(R).to(device)\n",
    "    reconstructed = ae_model(R_tensor).cpu().numpy()\n",
    "\n",
    "preds, actuals = [], []\n",
    "for row in test_df.itertuples():\n",
    "    preds.append(reconstructed[row.user, row.item])\n",
    "    actuals.append(row.rating)\n",
    "\n",
    "preds = np.array(preds)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "rmse_ae = np.sqrt(np.mean((preds - actuals) ** 2))\n",
    "mae_ae  = np.mean(np.abs(preds - actuals))\n",
    "print(f\"AutoRec Test RMSE: {rmse_ae:.4f}\")\n",
    "print(f\"AutoRec Test MAE:  {mae_ae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aaba20",
   "metadata": {},
   "source": [
    "## Full reconstructed matrix once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91bf22f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we already did this in the eval cell\n",
    "ae_model.eval()\n",
    "with torch.no_grad():\n",
    "    R_tensor = torch.from_numpy(R).to(device)\n",
    "    R_pred = ae_model(R_tensor).cpu().numpy()   # shape: (n_users, n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f6eb96",
   "metadata": {},
   "source": [
    "### Top-N function for AutoRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b61d5490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_autoRec(user_id, R_pred, train_df, idx2title, n=10):\n",
    "\n",
    "    # 1. Which items has this user already rated?\n",
    "    seen = set(train_df[train_df['user'] == user_id]['item'].values)\n",
    "\n",
    "    # 2. Compile a list of (item_idx, predicted_score) for unseen items\n",
    "    candidates = [\n",
    "        (i, R_pred[user_id, i])\n",
    "        for i in range(R_pred.shape[1])\n",
    "        if i not in seen\n",
    "    ]\n",
    "\n",
    "    # 3. Sort descending by score and take top-n\n",
    "    top_n = sorted(candidates, key=lambda x: x[1], reverse=True)[:n]\n",
    "    top_indices = [i for i, _ in top_n]\n",
    "\n",
    "    # 4. Map indices back to titles\n",
    "    return [idx2title[i] for i in top_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc693bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, \"One Flew Over the Cuckoo's Nest (1975)\"),\n",
       " (1, 'James and the Giant Peach (1996)'),\n",
       " (2, 'My Fair Lady (1964)'),\n",
       " (3, 'Erin Brockovich (2000)'),\n",
       " (4, \"Bug's Life, A (1998)\")]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(\n",
    "    \"data/movies.dat\",\n",
    "    sep=\"::\",\n",
    "    engine=\"python\",\n",
    "    names=[\"item\", \"title\", \"genres\"],\n",
    "    encoding=\"latin-1\"\n",
    ")\n",
    "\n",
    "idx2item = {new_idx: orig_id for orig_id, new_idx in item2idx.items()}\n",
    "\n",
    "idx2title = {\n",
    "    new_idx: movies.loc[movies[\"item\"] == orig_id, \"title\"].values[0]\n",
    "    for new_idx, orig_id in idx2item.items()\n",
    "}\n",
    "\n",
    "# Quick sanity check\n",
    "list(idx2title.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb88cfc",
   "metadata": {},
   "source": [
    "### Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f9fa1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoRec Top-10 for user 0:\n",
      "1. Beyond Rangoon (1995)\n",
      "2. Castle, The (1997)\n",
      "3. Heaven's Burning (1997)\n",
      "4. Umbrellas of Cherbourg, The (Parapluies de Cherbourg, Les) (1964)\n",
      "5. Trust (1990)\n",
      "6. Kundun (1997)\n",
      "7. Man for All Seasons, A (1966)\n",
      "8. 400 Blows, The (Les Quatre cents coups) (1959)\n",
      "9. Soldier's Daughter Never Cries, A (1998)\n",
      "10. Dersu Uzala (1974)\n"
     ]
    }
   ],
   "source": [
    "user_id = 0\n",
    "top10_autoRec = recommend_autoRec(user_id, R_pred, train_df, idx2title, n=10)\n",
    "\n",
    "print(f\"AutoRec Top-10 for user {user_id}:\")\n",
    "for rank, title in enumerate(top10_autoRec, 1):\n",
    "    print(f\"{rank}. {title}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
